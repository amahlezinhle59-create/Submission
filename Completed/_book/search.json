[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final Version of Assignment One",
    "section": "",
    "text": "Assignment One",
    "crumbs": [
      "Assignment One"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Final Version of Assignment One",
    "section": "Welcome",
    "text": "Welcome\nDear fellow survivor of this course ♡\nIf you are reading this, we have both made it this far, congratulations to us! I hope this assignment makes sense, runs without errors, and causes minimal emotional damage.\nMay your marking be fair, your coffee strong, and your rubric generous.",
    "crumbs": [
      "Assignment One"
    ]
  },
  {
    "objectID": "Project One.html",
    "href": "Project One.html",
    "title": "1  Project One",
    "section": "",
    "text": "♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION ONE ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\ndown &lt;- nrow(airquality)\nacross &lt;- ncol(airquality)\nsum &lt;- 0\n\nprint('The following rows have missing information: ')\n\n[1] \"The following rows have missing information: \"\n\nfor(i in 1:down){\n  for(j in 1:across){\n    if(is.na(airquality[i,j])){\n      sum &lt;- sum + 1\n      print(i)\n      break}\n  }\n}\n\n[1] 5\n[1] 6\n[1] 10\n[1] 11\n[1] 25\n[1] 26\n[1] 27\n[1] 32\n[1] 33\n[1] 34\n[1] 35\n[1] 36\n[1] 37\n[1] 39\n[1] 42\n[1] 43\n[1] 45\n[1] 46\n[1] 52\n[1] 53\n[1] 54\n[1] 55\n[1] 56\n[1] 57\n[1] 58\n[1] 59\n[1] 60\n[1] 61\n[1] 65\n[1] 72\n[1] 75\n[1] 83\n[1] 84\n[1] 96\n[1] 97\n[1] 98\n[1] 102\n[1] 103\n[1] 107\n[1] 115\n[1] 119\n[1] 150\n\nprint(paste0('In total there are ', sum, ' rows with missing information.' ))\n\n[1] \"In total there are 42 rows with missing information.\"\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION TWO ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\nmy_table &lt;- data.frame(\n  Column = c('Temperature', 'Ozone'),\n  Mean = c(mean(airquality[,4]), mean(airquality[,1], na.rm=TRUE)),\n  SD = c(sd(airquality[,4]), sd(airquality[,1], na.rm=TRUE)),\n  Min = c(min(airquality[,4]), min(airquality[,1], na.rm=TRUE)),\n  Max = c(max(airquality[,4]), max(airquality[,1], na.rm=TRUE))\n)\n\nprint(my_table)\n\n       Column     Mean       SD Min Max\n1 Temperature 77.88235  9.46527  56  97\n2       Ozone 42.12931 32.98788   1 168\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION THREE ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\ndata(cars)\n\nY &lt;- cars$dist\nX &lt;- cbind(1, cars$speed)\n\nmy_funct &lt;- function(design, response) {\n  \n  a &lt;- t(design)%*%design\n  b &lt;- solve(a)\n  c &lt;- t(design)%*%response\n  d &lt;- b%*%c\n  \n  return(d)\n}\n\nprint(my_funct(X, Y))\n\n           [,1]\n[1,] -17.579095\n[2,]   3.932409\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION FOUR ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\nmodel &lt;- lm(cars$dist~cars$speed, data=cars )\nsummary(model)\n\n\nCall:\nlm(formula = cars$dist ~ cars$speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \ncars$speed    3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project One</span>"
    ]
  },
  {
    "objectID": "Day Three Practical Q3 & Q4.html",
    "href": "Day Three Practical Q3 & Q4.html",
    "title": "2  Day Three Practical Q3 & Q4",
    "section": "",
    "text": "♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION FOUR ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\ncurve(sin(x), from = -2, to = 2)\n\n\n\n\n\n\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION FIVE ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\nrandoms &lt;- rt(1000, 1)\n\n#Creating a manual QQ-plot with 95% confidence interval\n\nsorted_randoms &lt;- sort(randoms)\n\nn &lt;- length(randoms)\ni &lt;- 1:n\n\n# Calculate plotting positions (probabilities)\np &lt;- (i - 3/8) / (n + 1/4)\n\n# Generate normal quantiles by simulation (since we can't use qnorm)\nlarge_normal_sample &lt;- rnorm(1000000)  # Large normal reference\ntheoretical_quantiles &lt;- quantile(large_normal_sample, probs = p)\n\n# Calculate 95% probability envelopes by simulation\nn_sim &lt;- 1000  # Number of simulations\nenvelope_matrix &lt;- matrix(NA, nrow = n_sim, ncol = n)\n\n# Simulate many normal samples of size n\nfor (j in 1:n_sim) {\n    sim_sample &lt;- rnorm(n)\n    sim_sorted &lt;- sort(sim_sample)\n    envelope_matrix[j, ] &lt;- sim_sorted\n}\n\n# Calculate 2.5% and 97.5% percentiles at each position\nlower_envelope &lt;- apply(envelope_matrix, 2, quantile, probs = 0.025)\nupper_envelope &lt;- apply(envelope_matrix, 2, quantile, probs = 0.975)\n\n# Create the QQ-plot\npar(mfrow = c(1, 2))  # Split plot window\n\n# Manual QQ-plot\nplot(theoretical_quantiles, sorted_randoms,\n     xlab = \"Theoretical Normal Quantiles\",\n     ylab = \"Sample Quantiles\",\n     main = \"Manual QQ-plot with 95% Envelopes\",\n     pch = 19, cex = 0.6,\n     ylim = c(-5, 5), xlim = c(-4, 4),\n     col = rgb(0, 0, 0, 0.7))\n\n# Add reference line (y = x)\nabline(a = 0, b = 1, col = \"red\", lwd = 2)\n\n# Add 95% probability bands\nlines(theoretical_quantiles, lower_envelope, \n      col = \"blue\", lty = 2, lwd = 2)\nlines(theoretical_quantiles, upper_envelope, \n      col = \"blue\", lty = 2, lwd = 2)\n\n# Add legend\nlegend(\"topleft\", \n       legend = c(\"Data\", \"Reference Line\", \"95% Envelope\"),\n       col = c(\"black\", \"red\", \"blue\"),\n       pch = c(19, NA, NA),\n       lty = c(NA, 1, 2),\n       lwd = c(NA, 2, 2))\n\n# Check with car::qqPlot for comparison\nlibrary(car)\n\nLoading required package: carData\n\nqqPlot(randoms, envelope = 0.95, ylim = c(-5, 5),\n       main = \"car::qqPlot for Comparison\",\n       xlab = \"Normal Quantiles\",\n       ylab = \"Sample Quantiles\")\n\n\n\n\n\n\n\n\n[1] 855 144",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Day Three Practical Q3 & Q4</span>"
    ]
  },
  {
    "objectID": "Day Four Practical.html",
    "href": "Day Four Practical.html",
    "title": "3  Day Four Practical",
    "section": "",
    "text": "♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION ONE ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   4.0.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\nWarning: package 'nycflights13' was built under R version 4.3.3\n\n#The line below renames the first 10 columns of flights and prints the flights data set with the arrival times arranged in ascending order\n\nflights |&gt; rename(Year = year, Month = month, Day = day, Dep_Time = dep_time, Sched_Dep_Time = sched_dep_time, Dep_Delay = dep_delay, Arr_Time = arr_time, Sched_Arr_Time = sched_arr_time, Arr_Delay = arr_delay, Carrier = carrier) |&gt; arrange(Arr_Time)\n\n# A tibble: 336,776 × 19\n    Year Month   Day Dep_Time Sched_Dep_Time Dep_Delay Arr_Time Sched_Arr_Time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     2     2130           2130         0        1             18\n 2  2013     1    11     2157           2000       117        1           2208\n 3  2013     1    11     2253           2249         4        1           2357\n 4  2013     1    14     2122           2130        -8        1              2\n 5  2013     1    14     2246           2250        -4        1              7\n 6  2013     1    15     2304           2245        19        1           2357\n 7  2013     1    16     2018           2025        -7        1           2329\n 8  2013     1    16     2303           2245        18        1           2357\n 9  2013     1    19     2107           2110        -3        1           2355\n10  2013     1    22     2246           2249        -3        1           2357\n# ℹ 336,766 more rows\n# ℹ 11 more variables: Arr_Delay &lt;dbl&gt;, Carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION TWO ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\n#Creates flight1 tibble that contains flights that occured in month 1 ONLY\nflight1 &lt;- flights |&gt; filter(month == 1)\n\n#Gets the average distance of each carrier\ncarrier_dist_vec_mean &lt;- flight1 |&gt; group_by(carrier) |&gt; summarise(MEAN = mean(distance, na.rm = TRUE ))\n\n#Gets the standard deviation of the distance for each carrier\ncarrier_dist_vec_sd &lt;- flight1 |&gt; group_by(carrier) |&gt; summarise(SD = sd(distance, na.rm = TRUE))\n\n#Creates one tibble with both the mean and sd distance for each carrier\ndist_tbl &lt;- carrier_dist_vec_mean |&gt; left_join(carrier_dist_vec_sd)\n\nJoining with `by = join_by(carrier)`\n\n#Arranges the carrier rows from that with the least to the highest mean distance\ndist_tbl |&gt; arrange(MEAN)\n\n# A tibble: 16 × 3\n   carrier  MEAN    SD\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 YV       229    0  \n 2 9E       476. 334. \n 3 EV       522. 294. \n 4 US       536. 553. \n 5 MQ       566. 223. \n 6 FL       691. 142. \n 7 OO       733   NA  \n 8 WN       942. 496. \n 9 B6      1062. 681. \n10 DL      1220. 644. \n11 AA      1350. 626. \n12 UA      1462. 778. \n13 F9      1620    0  \n14 AS      2402    0  \n15 VX      2495.  98.2\n16 HA      4983    0  \n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION THREE ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\n########## NA #############\n\ncarrierOO &lt;- flight1 |&gt; filter(carrier == 'OO') |&gt; select(carrier, distance)\n\ncarrierOO\n\n# A tibble: 1 × 2\n  carrier distance\n  &lt;chr&gt;      &lt;dbl&gt;\n1 OO           733\n\nprint('Explanation of NA: Carrier OO has NA as the standard deviation of the distance, that is because as shown by the code above, there is only one entry thus the standard deviation can\\'t be calculated since sd is a measure of how spread apart data points are from each other, with only one distance entry there is no spread.')\n\n[1] \"Explanation of NA: Carrier OO has NA as the standard deviation of the distance, that is because as shown by the code above, there is only one entry thus the standard deviation can't be calculated since sd is a measure of how spread apart data points are from each other, with only one distance entry there is no spread.\"\n\n########## ZERO ##############\n\ncarrierYV &lt;- flight1 |&gt; filter(carrier == 'YV') |&gt; select(carrier, distance)\n\ncarrierYV\n\n# A tibble: 46 × 2\n   carrier distance\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 YV           229\n 2 YV           229\n 3 YV           229\n 4 YV           229\n 5 YV           229\n 6 YV           229\n 7 YV           229\n 8 YV           229\n 9 YV           229\n10 YV           229\n# ℹ 36 more rows\n\nprint('Explanaition of ZERO: The standard deviation of the distance for the YV carrier is zero because as displayed by the code above, all the distance entries are 229, sd is a measure of how spread apart entries are from each other, in this case they are all the same thus resulting in no spread or a spread of zero.')\n\n[1] \"Explanaition of ZERO: The standard deviation of the distance for the YV carrier is zero because as displayed by the code above, all the distance entries are 229, sd is a measure of how spread apart entries are from each other, in this case they are all the same thus resulting in no spread or a spread of zero.\"\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION FOUR ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\n#Getting the Average Departure delay for each carrier in each month in the long format\nswitched &lt;- flights |&gt; group_by(carrier, month) |&gt; summarise(Av_Dep_Delay = mean(dep_delay, na.rm = TRUE)) \n\n`summarise()` has grouped output by 'carrier'. You can override using the\n`.groups` argument.\n\n#Converting into wide data\nswitched2 &lt;- switched |&gt; pivot_wider(names_from = carrier, values_from = Av_Dep_Delay)\n\nswitched2\n\n# A tibble: 12 × 17\n   month  `9E`    AA     AS    B6    DL    EV    F9    FL    HA    MQ    OO\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 16.9   6.93  7.35   9.49  3.85 24.2  10     1.97 54.4   6.49 67   \n 2     2 16.5   8.28  0.722 13.8   5.54 21.5  29.8   5.18 17.4   8.09 NA   \n 3     3 13.4   8.70  8.42  14.2   9.93 26.2  16.8  17.3   1.16  7.19 NA   \n 4     4 13.6  11.7  11.3   15.2   8.17 22.8  24.6  13.1  -2.1  13.7  NA   \n 5     5 22.7   9.66  6.77   9.78  9.74 20.2  35.9  19.2  -1.45 13.9  NA   \n 6     6 29.0  14.6  13.1   20.4  18.7  25.5  29.4  38.8   1.47 20.8  61   \n 7     7 31.4  12.1   2.42  24.9  20.6  26.5  31.8  41.2  -1.71 20.7  NA   \n 8     8 17.3   7.17  2.87  15.7   9.85 16.3  22.2  23.4   1.68 10.1  64   \n 9     9  7.75  5.69 -4.52   6.63  5.53  8.24  8.26 16.9  -5.44  5.35 -4.94\n10    10  9.33  3.00  0.677  2.96  3.42 13.4   9.70 13.7  -5.10  4.48 NA   \n11    11  7.56  3.10  3.08   3.52  2.85  9.83 13.5  16.9  -5.44  3.28  0.8 \n12    12 19.8  11.7  18.0   17.0  10.8  27.9  13.1  26.1  -3.14 12.7  NA   \n# ℹ 5 more variables: UA &lt;dbl&gt;, US &lt;dbl&gt;, VX &lt;dbl&gt;, WN &lt;dbl&gt;, YV &lt;dbl&gt;\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION FIVE ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\n#Getting number of all flights with a delayed departure time and arrived with NO delay\nmeet_Condition &lt;- flights |&gt; filter(dep_delay &gt; 0) |&gt; filter(arr_delay &lt;= 0) |&gt; count()\n\n#Getting number of total flights\ntotal_Flights &lt;- flights |&gt; count()\n\n#Calculating the proportion\nprop_Delayed &lt;- meet_Condition/total_Flights\n\n#Renaming the column\nprop_Delayed &lt;- prop_Delayed |&gt; rename(Prop_Delayed = n)\n\nprop_Delayed\n\n  Prop_Delayed\n1    0.1052391\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION SIX ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\nroutes &lt;- flights |&gt; group_by(origin, dest) |&gt; summarize(n_airlines = n_distinct(carrier)) |&gt; filter(n_airlines &gt; 1)\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nroutes\n\n# A tibble: 128 × 3\n# Groups:   origin [3]\n   origin dest  n_airlines\n   &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;\n 1 EWR    ATL            4\n 2 EWR    AUS            2\n 3 EWR    BDL            2\n 4 EWR    BNA            2\n 5 EWR    BOS            3\n 6 EWR    BWI            2\n 7 EWR    CHS            2\n 8 EWR    CLE            2\n 9 EWR    CLT            3\n10 EWR    CVG            2\n# ℹ 118 more rows\n\n\n\n#Joining the routes with at least two airlines with rest of the flights data\njoint &lt;- routes |&gt; left_join(flights, by = join_by(origin, dest))\n\n#Grouping to get each route+carrier combo then calc it's average arrival delay\njoint2 &lt;- joint |&gt; group_by(origin, dest, carrier) |&gt; summarise(Av_Arr_Delay = mean(arr_delay, na.rm = TRUE))\n\n`summarise()` has grouped output by 'origin', 'dest'. You can override using\nthe `.groups` argument.\n\njoint2\n\n# A tibble: 343 × 4\n# Groups:   origin, dest [128]\n   origin dest  carrier Av_Arr_Delay\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1 EWR    ATL   9E             -6.25\n 2 EWR    ATL   DL             10.00\n 3 EWR    ATL   EV             19.5 \n 4 EWR    ATL   UA             10.5 \n 5 EWR    AUS   UA              4.28\n 6 EWR    AUS   WN            -11.2 \n 7 EWR    BDL   EV              6.78\n 8 EWR    BDL   UA             22.6 \n 9 EWR    BNA   EV             17.7 \n10 EWR    BNA   WN             -2.13\n# ℹ 333 more rows\n\n\n\n# Airline with the best average arrival delay\n\nbest &lt;- joint2 |&gt; group_by(origin, dest) |&gt; summarise(best_av_arr_delay = min(Av_Arr_Delay))\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nbest2 &lt;- best |&gt; left_join(joint2, join_by(best_av_arr_delay == Av_Arr_Delay)) |&gt; select(!origin.y) |&gt; select(!dest.y)\n\nWarning in left_join(best, joint2, join_by(best_av_arr_delay == Av_Arr_Delay)): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 17 of `x` matches multiple rows in `y`.\nℹ Row 41 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nbest2\n\n# A tibble: 134 × 4\n   origin.x dest.x best_av_arr_delay carrier\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;  \n 1 EWR      ATL               -6.25  9E     \n 2 EWR      AUS              -11.2   WN     \n 3 EWR      BDL                6.78  EV     \n 4 EWR      BNA               -2.13  WN     \n 5 EWR      BOS               -4.01  EV     \n 6 EWR      BWI                5.95  WN     \n 7 EWR      CHS              -14     UA     \n 8 EWR      CLE               -3.71  EV     \n 9 EWR      CLT                0.920 US     \n10 EWR      CVG                1.40  9E     \n# ℹ 124 more rows\n\n#Airline with the worst arrival delay\n\nworst &lt;- joint2 |&gt; group_by(origin, dest) |&gt; summarise(worst_av_arr_delay = max(Av_Arr_Delay))\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nworst2 &lt;- worst |&gt; left_join(joint2, join_by(worst_av_arr_delay == Av_Arr_Delay)) |&gt; select(!origin.y) |&gt; select(!dest.y)\n\nWarning in left_join(worst, joint2, join_by(worst_av_arr_delay == Av_Arr_Delay)): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 75 of `x` matches multiple rows in `y`.\nℹ Row 194 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nworst2\n\n# A tibble: 130 × 4\n   origin.x dest.x worst_av_arr_delay carrier\n   &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;  \n 1 EWR      ATL                 19.5  EV     \n 2 EWR      AUS                  4.28 UA     \n 3 EWR      BDL                 22.6  UA     \n 4 EWR      BNA                 17.7  EV     \n 5 EWR      BOS                  6.87 B6     \n 6 EWR      BWI                 20.1  EV     \n 7 EWR      CHS                 16.2  EV     \n 8 EWR      CLE                  5.97 UA     \n 9 EWR      CLT                 20.5  EV     \n10 EWR      CVG                 21.2  EV     \n# ℹ 120 more rows\n\n#Combining\n\nresults &lt;- best2 |&gt; left_join(worst2, join_by(origin.x, dest.x))\n\nWarning in left_join(best2, worst2, join_by(origin.x, dest.x)): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 77 of `x` matches multiple rows in `y`.\nℹ Row 17 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nresults\n\n# A tibble: 136 × 6\n   origin.x dest.x best_av_arr_delay carrier.x worst_av_arr_delay carrier.y\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;    \n 1 EWR      ATL               -6.25  9E                     19.5  EV       \n 2 EWR      AUS              -11.2   WN                      4.28 UA       \n 3 EWR      BDL                6.78  EV                     22.6  UA       \n 4 EWR      BNA               -2.13  WN                     17.7  EV       \n 5 EWR      BOS               -4.01  EV                      6.87 B6       \n 6 EWR      BWI                5.95  WN                     20.1  EV       \n 7 EWR      CHS              -14     UA                     16.2  EV       \n 8 EWR      CLE               -3.71  EV                      5.97 UA       \n 9 EWR      CLT                0.920 US                     20.5  EV       \n10 EWR      CVG                1.40  9E                     21.2  EV       \n# ℹ 126 more rows\n\n\n\nresults2 &lt;- results |&gt; mutate(diff = sqrt((best_av_arr_delay - worst_av_arr_delay)**2)) \n\nresults3 &lt;- results2 |&gt; summarise(greatest_diff = max(diff, na.rm = TRUE)) |&gt; left_join(results2, join_by(greatest_diff == diff ))\n\nresults3\n\n# A tibble: 1 × 7\n  greatest_diff origin.x dest.x best_av_arr_delay carrier.x worst_av_arr_delay\n          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1          127. JFK      ATL                 1.40 9E                       128\n# ℹ 1 more variable: carrier.y &lt;chr&gt;\n\n\n\n#Trying to find the reason\n\nreason &lt;- results |&gt; mutate(diff = sqrt((best_av_arr_delay - worst_av_arr_delay)**2))\n\nreason2 &lt;- reason |&gt; summarise(terrible = max(worst_av_arr_delay, na.rm = TRUE))\n\nreason2\n\n# A tibble: 1 × 1\n  terrible\n     &lt;dbl&gt;\n1      128\n\nprint('The above code shows that the worst average arrival delay was 128, it so happens that this corresponds with the route with the greatest diff (it\\'s an outlier), their average arrival delay was too much thus creating the large difference between their best and worst av. arr delay.')\n\n[1] \"The above code shows that the worst average arrival delay was 128, it so happens that this corresponds with the route with the greatest diff (it's an outlier), their average arrival delay was too much thus creating the large difference between their best and worst av. arr delay.\"\n\n\n♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡ QUESTION SEVEN ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n\ngiven_data &lt;- structure(list(id = c(\"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\", \n\"id_6\", \"id_7\", \"id_8\", \"id_9\", \"id_10\", \"id_11\", \"id_12\", \"id_13\", \n\"id_14\", \"id_15\", \"id_16\", \"id_17\", \"id_18\", \"id_19\", \"id_20\", \n\"id_21\", \"id_22\", \"id_23\", \"id_24\", \"id_25\", \"id_26\", \"id_27\", \n\"id_28\", \"id_29\", \"id_30\", \"id_31\", \"id_32\", \"id_33\", \"id_34\", \n\"id_35\", \"id_36\", \"id_37\", \"id_38\", \"id_39\", \"id_40\", \"id_41\", \n\"id_42\", \"id_43\", \"id_44\", \"id_45\", \"id_46\", \"id_47\", \"id_48\", \n\"id_49\", \"id_50\"), age = c(50L, 34L, 70L, 33L, 22L, 61L, 69L, \n73L, 62L, 56L, 71L, 33L, 73L, 44L, 45L, 46L, 24L, 70L, 46L, 76L, \n47L, 76L, 28L, 48L, 54L, 27L, 45L, 26L, 61L, 28L, 38L, 55L, 33L, \n36L, 62L, 58L, 72L, 31L, 34L, 51L, 61L, 64L, 26L, 28L, 60L, 29L, \n42L, 46L, 79L, 72L), gender = c(\"male\", \"male\", \"male\", \"female\", \n\"female\", \"male\", \"female\", \"male\", \"male\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"male\", \"male\", \"male\", \"female\", \n\"male\", \"male\", \"male\", \"male\", \"female\", \"femal\", \"male\", \"female\", \n\"female\", \"female\", \"female\", \"male\", \"female\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"male\", \n\"female\", \"female\", \"male\", \"male\", \"female\", \"male\", \"male\", \n\"male\", \"female\"), height = c(174.4, 197.7, 174.1, 194.5, NA, \n180.4, 170.5, 157.4, 196.8, 165.1, 153, 197.4, 186, 157.1, 177.5, \n197.7, 179.3, 170.2, 182.4, NA, 165.4, 161, 168.5, 199.2, 157.7, \n154.6, 157.1, 184.5, 181, 194.6, 183.6, 186.9, 176.1, 183, 191.1, \n189.3, 199, 172, 165.6, 170.5, 150.5, 159.2, 192.1, 161.6, 162, \n153.8, 162.3, 186.6, 192.4, 174.9), weight = c(69.4, 62.3, 55.6, \n69.5, 78.6, 60.8, 72.2, 60.9, 75.1, 67.7, 82.5, 68.7, 67.8, 76.7, \n87, 61.1, 70.6, 63.3, 81.5, 59.2, 93.2, 87.3, 83.4, 80.9, 68.6, \n76.5, 93.7, 79.1, 92, 65.6, 85.4, 63.3, 79.7, 74.1, 63.3, 78.2, \n95.7, 95.1, 63.7, 66.1, 99.3, 81, 96.9, 73.3, 70.3, 83, 57.6, \n78.6, 61.9, 98.1), blood_type = c(\"O\", \"A\", \"O\", \"O\", \"B\", \"AB\", \n\"O\", \"O\", \"O\", \"AB\", \"A\", \"O\", \"O\", \"O\", \"B\", \"A\", \"B\", \"AB\", \n\"O\", \"AB\", \"A\", \"AB\", \"O\", \"B\", \"A\", \"A\", \"B\", \"AB\", \"A\", \"B\", \n\"B\", \"A\", \"O\", \"O\", \"O\", \"B\", \"O\", \"A\", \"A\", \"B\", \"A\", \"O\", \"AB\", \n\"A\", \"A\", \"O\", \"O\", \"B\", \"A\", \"O\"), disease_status = c(\"diseased\", \n\"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"Healthy\", \"diseased\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"healthy\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"healthy\", \"diseased\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"diseased\", \"diseased\", \"healthy\", \n\"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"diseased\", \"diseased\", \"diseased\", \"healthy\", \"healthy\", \"diseased\", \n\"diseased\"), cholesterol = c(228, 223, 213, 198, 166, 151, 195, \n199, 189, 196, 221, 156, 185, 230, 234, 174, 185, 236, 235, 180, \n165, 220, 160, 153, 250, 153, 184, 242, 212, 179, 224, 233, 181, \n199, 220, 214, 214, 248, 191, 162, 203, 173, 199, 187, 248, 189, \n173, 212, 164, 247), glucose = c(96, 78, 101, 119, 103, 91, 86, \nNA, 77, 80, 115, 85, 88, 109, NA, 71, 90, 94, 91, 87, 113, 93, \n97, 118, 109, 80, 85, 119, 99, 108, 89, 108, 97, 116, 79, 84, \n75, 81, 119, NA, 106, 109, 75, 82, 84, 75, 76, 120, 119, 77), \n    smoker = c(\"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"no\", \n    \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \n    \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \n    \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\"), exercise = c(\"occasional\", \n    \"regular\", \"occasional\", \"regular\", \"none\", \"occasional\", \n    \"regular\", \"none\", \"occasional\", \"none\", \"occasional\", \"none\", \n    \"none\", \"regular\", \"occasional\", \"none\", \"regular\", \"regular\", \n    \"none\", \"occasional\", \"none\", \"occasional\", \"occasional\", \n    \"occasional\", \"regular\", \"occasional\", \"regular\", \"regular\", \n    \"regular\", \"occasional\", \"occasional\", \"none\", \"none\", \"regular\", \n    \"occasional\", \"occasional\", \"none\", \"none\", \"none\", \"none\", \n    \"occasional\", \"regular\", \"regular\", \"none\", \"regular\", \"occasional\", \n    \"occasional\", \"none\", \"occasional\", \"regular\"), income = c(84820L, \n    81547L, 22588L, 72490L, 74533L, 25338L, 41469L, 57315L, 63629L, \n    88662L, 62615L, 56261L, 58499L, 82232L, 77584L, 77275L, 38468L, \n    54510L, 91326L, 78611L, 31402L, 29586L, 21441L, 58269L, 84173L, \n    88295L, 37940L, 43750L, 69750L, 92356L, 82518L, 91455L, 68866L, \n    51178L, 68275L, 27689L, 35418L, 81318L, 62405L, 86851L, 25654L, \n    47553L, 74474L, 51409L, 22607L, 55360L, 96351L, 21516L, 41927L, \n    55810L), education = c(\"master\", \"bachelor\", \"PhD\", \"master\", \n    \"bachelor\", \"highschool\", \"PhD\", \"highschool\", \"PhD\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"bachelor\", \"PhD\", \"PhD\", \n    \"PhD\", \"bachelor\", \"master\", \"highschool\", \"PhD\", \"highschool\", \n    \"bachelor\", \"master\", \"highschool\", \"highschool\", \"master\", \n    \"master\", \"bachelor\", \"PhD\", \"highschool\", \"PhD\", \"master\", \n    \"master\", \"master\", \"PhD\", \"highschool\", \"master\", \"master\", \n    \"highschool\", \"bachelor\", \"highschool\", \"bachelor\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"highschool\", \"bachelor\", \n    \"bachelor\"), region = c(\"North\", \"South\", \"North\", \"West\", \n    \"North\", \"West\", \"South\", \"South\", \"West\", \"South\", \"West\", \n    \"South\", \"West\", \"East\", \"North\", \"West\", \"North\", \"North\", \n    \"West\", \"North\", \"East\", \"West\", \"South\", \"North\", \"North\", \n    \"East\", \"East\", \"North\", \"North\", \"West\", \"South\", \"West\", \n    \"West\", \"East\", \"West\", \"North\", \"West\", \"North\", \"East\", \n    \"North\", \"West\", \"South\", \"South\", \"East\", \"North\", \"West\", \n    \"West\", \"East\", \"North\", \"East\"), marital_status = c(\"divorced\", \n    \"single\", \"divorced\", \"divorced\", \"divorced\", \"divorced\", \n    \"divorced\", \"married\", \"divorced\", \"married\", \"divorced\", \n    \"widowed\", \"married\", \"single\", \"widowed\", \"widowed\", \"single\", \n    \"divorced\", \"widowed\", \"widowed\", \"single\", \"married\", \"single\", \n    \"married\", \"widowed\", \"married\", \"single\", \"single\", \"widowed\", \n    \"married\", \"widowed\", \"divorced\", \"single\", \"married\", \"single\", \n    \"widowed\", \"widowed\", \"married\", \"widowed\", \"divorced\", \"married\", \n    \"married\", \"divorced\", \"single\", \"married\", \"widowed\", \"divorced\", \n    \"divorced\", \"single\", \"divorced\")), row.names = c(NA, -50L\n), class = c(\"tbl_df\", \"tbl\", \"data.frame\"))\n\nlibrary(UtilsDataRSV)\nsee &lt;- given_data |&gt; view_cols()\n\n[1] \"id\"\n [1] \"id_3\"  \"id_30\" \"id_2\"  \"id_31\" \"id_14\" \"id_21\" \"id_4\"  \"id_43\" \"id_48\"\n[10] \"id_40\" \"id_35\" \"id_44\" \"id_1\"  \"id_37\" \"id_50\" \"id_42\" \"id_16\" \"id_45\"\n[19] \"id_34\" \"id_22\"\n[1] \"30 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"age\"\n[1] 62 72 70 33 45\n[1] \"_____________________\"\n[1] \"gender\"\n[1] \"femal\"  \"male\"   \"female\"\n[1] \"_____________________\"\n[1] \"height\"\n[1] 192.1 161.0 153.8 189.3    NA\n[1] \"_____________________\"\n[1] \"weight\"\n[1] 65.6 60.9 93.2 76.5 69.4\n[1] \"_____________________\"\n[1] \"blood_type\"\n[1] \"AB\" \"O\"  \"B\"  \"A\" \n[1] \"_____________________\"\n[1] \"disease_status\"\n[1] \"Healthy\"  \"diseased\" \"healthy\" \n[1] \"_____________________\"\n[1] \"cholesterol\"\n[1] 153 195 160 164 179\n[1] \"_____________________\"\n[1] \"glucose\"\n[1] 108  81 120  88  NA\n[1] \"_____________________\"\n[1] \"smoker\"\n[1] \"no\"  \"yes\"\n[1] \"_____________________\"\n[1] \"exercise\"\n[1] \"regular\"    \"occasional\" \"none\"      \n[1] \"_____________________\"\n[1] \"income\"\n[1] 54510 21516 58499 84173 91326\n[1] \"_____________________\"\n[1] \"education\"\n[1] \"bachelor\"   \"PhD\"        \"highschool\" \"master\"    \n[1] \"_____________________\"\n[1] \"region\"\n[1] \"West\"  \"North\" \"South\" \"East\" \n[1] \"_____________________\"\n[1] \"marital_status\"\n[1] \"widowed\"  \"divorced\" \"single\"   \"married\" \n[1] \"_____________________\"\n\n\nWarning: Not all unique entries displayed for these non-numeric cols: id\n\nprint('LIST OF ERRORS: ')\n\n[1] \"LIST OF ERRORS: \"\n\nprint('♡From the above we can see that the gender column has a typo: \\'femal\\' instead of \\'female\\'. ')\n\n[1] \"♡From the above we can see that the gender column has a typo: 'femal' instead of 'female'. \"\n\nprint('♡The height column has some missing entries.')\n\n[1] \"♡The height column has some missing entries.\"\n\nprint('♡The disease_status column has a typo, \\'Healthy\\' and \\'healthy\\'.')\n\n[1] \"♡The disease_status column has a typo, 'Healthy' and 'healthy'.\"\n\nprint('♡The glucose column has some missing entries.')\n\n[1] \"♡The glucose column has some missing entries.\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Day Four Practical</span>"
    ]
  }
]